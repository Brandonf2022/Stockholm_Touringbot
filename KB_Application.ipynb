{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file path: /Users/brandonfarnsworth/Library/Mobile Documents/com~apple~CloudDocs/Post-Phd/Published Texts/Method Article Collecting Trace Data using LLM/Lokal_Datablad_Original.xlsx\n",
      "Today's date: 2024-06-30\n",
      "Start year for data fetching: 1908\n",
      "Years to crawl: 1\n",
      "Name of newspaper: Svenska Dagbladet\n",
      "Valid options for newspapers: ['Dagens nyheter', 'Svenska Dagbladet', 'Aftonbladet', 'Dagligt Allehanda']\n",
      "KB API Max Retries: 10\n",
      "KB API Max Retry Time: 300\n",
      "\n",
      "DataFrame preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lokal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La Croix salong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Norra paviljongen i Trädgårdsföreningens lokal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wallmans lokal (Mäster Samuels gränd 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kungliga operan/Kungliga teatern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F.d. Kirsteinska huset (vid Clara) [Hotel W6 r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Lokal\n",
       "0                                    La Croix salong\n",
       "1     Norra paviljongen i Trädgårdsföreningens lokal\n",
       "2           Wallmans lokal (Mäster Samuels gränd 11)\n",
       "3                   Kungliga operan/Kungliga teatern\n",
       "4  F.d. Kirsteinska huset (vid Clara) [Hotel W6 r..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import backoff\n",
    "import requests\n",
    "from KBDownloader import fetch_newspaper_data\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Load configuration\n",
    "def load_config(config_path='config.yaml'):\n",
    "    with open(config_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "# Load the Excel file\n",
    "venue_list = pd.read_excel(config['venue_list'])\n",
    "\n",
    "# Get today's date\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Setup backoff for KB requests\n",
    "@backoff.on_exception(backoff.expo, \n",
    "                      (requests.exceptions.RequestException, requests.exceptions.HTTPError),\n",
    "                      max_tries=config['max_retries'],\n",
    "                      max_time=config['max_retry_time'])\n",
    "def fetch_with_backoff(*args, **kwargs):\n",
    "    return fetch_newspaper_data(*args, **kwargs)\n",
    "\n",
    "\n",
    "# Initialize start date for data fetching\n",
    "start_year = config['start_year']\n",
    "years_to_crawl = config['years_to_crawl']\n",
    "name_of_newspaper = config['newspaper']\n",
    "\n",
    "# Print out variables and assumptions\n",
    "print(f\"Excel file path: {config['venue_list']}\")\n",
    "print(f\"Today's date: {today_date}\")\n",
    "print(f\"Start year for data fetching: {config['start_year']}\")\n",
    "print(f\"Years to crawl: {config['years_to_crawl']}\")\n",
    "print(f\"Name of newspaper: {config['newspaper']}\")\n",
    "print(f\"Valid options for newspapers: {config['valid_newspapers']}\")\n",
    "print(f\"KB API Max Retries: {config['max_retries']}\")\n",
    "print(f\"KB API Max Retry Time: {config['max_retry_time']}\")\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify loading\n",
    "print(\"\\nDataFrame preview:\")\n",
    "display(venue_list.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Iteratively go through the venues (Lokale) and return the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed query 'La Croix salong' successfully.\n",
      "Waiting so KB does not get mad. Currently at 1908-01-01 00:00:00 to 1908-06-30 00:00:00\n",
      "Failed to process query 'Norra paviljongen i Trädgårdsföreningens lokal': No data to export. The list of data frames is empty.\n",
      "Waiting so KB does not get mad. Currently at 1908-01-01 00:00:00 to 1908-06-30 00:00:00\n",
      "Failed to process query 'Wallmans lokal (Mäster Samuels gränd 11)': No data to export. The list of data frames is empty.\n",
      "Waiting so KB does not get mad. Currently at 1908-01-01 00:00:00 to 1908-06-30 00:00:00\n",
      "Failed to process query 'Kungliga operan/Kungliga teatern': No data to export. The list of data frames is empty.\n",
      "Waiting so KB does not get mad. Currently at 1908-01-01 00:00:00 to 1908-06-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Main loop over the specified year range\n",
    "for year in range(start_year, start_year + years_to_crawl):\n",
    "    for half in range(2):  # Loop for each half of the year\n",
    "        if half == 0:\n",
    "            from_date = datetime(year, 1, 1)  # Start of the year\n",
    "            to_date = datetime(year, 6, 30)  # End of June\n",
    "        else:\n",
    "            from_date = datetime(year, 7, 1)  # Start of July\n",
    "            to_date = datetime(year, 12, 31)  # End of the year\n",
    "        \n",
    "        for index, row in venue_list.iterrows():\n",
    "            query = row['Lokal']\n",
    "            safe_query = \"\".join([c if c.isalnum() else \"_\" for c in query])\n",
    "            output_dir = f'extracted_data_{safe_query}_{today_date}'\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            output_filepath = os.path.join(output_dir, f'extracted_data_{safe_query}_{today_date}')\n",
    "            \n",
    "            try:\n",
    "                result = fetch_newspaper_data(\n",
    "                    query=query,\n",
    "                    from_date=from_date.strftime('%Y-%m-%d'),\n",
    "                    to_date=to_date.strftime('%Y-%m-%d'),\n",
    "                    newspaper=name_of_newspaper,\n",
    "                    prompt_filepath='oldtimey_touringbot_prompt_for_deployment.txt',\n",
    "                    output_filepath=output_filepath\n",
    "                )\n",
    "                \n",
    "                if result.get('success'):\n",
    "                    print(f\"Processed query '{query}' successfully.\")\n",
    "                else:\n",
    "                    print(f\"Failed to process query '{query}': {result.get('message')}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing query '{query}': {str(e)}\")\n",
    "                print(\"Continuing with the next query...\")\n",
    "            \n",
    "            # Wait for a minute after each query\n",
    "            print(f\"Waiting so KB does not get mad. Currently at {from_date} to {to_date}\")\n",
    "            time.sleep(10)\n",
    "\n",
    "print(\"All queries processed for all specified years.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Clean up: Data created in step 1 is concatenated into jsonl file, folders and XLSX files deleted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the path where the JSONL files are stored and where to save the final concatenated JSONL file\n",
    "final_jsonl_filename = f'final_data_{today_date}_{name_of_newspaper}.jsonl'\n",
    "\n",
    "# Define the base directory to start the search and the path for the output JSONL file\n",
    "base_directory = '/Users/brandonfarnsworth/Library/Mobile Documents/com~apple~CloudDocs/Post-Phd/Quantitative Work/Software/Oldtimey_touringbot/extracted_data29.05.'\n",
    "final_jsonl_filename = f'final_data_{today_date}_{name_of_newspaper}.jsonl'\n",
    "final_jsonl_filepath = os.path.join('/Users/brandonfarnsworth/Library/Mobile Documents/com~apple~CloudDocs/Post-Phd/Quantitative Work/Software/Oldtimey_touringbot/', final_jsonl_filename)  # Adjust the output file path as needed\n",
    "\n",
    "print(f\"Looking for JSONL files in {base_directory}\")\n",
    "print(f\"Final concatenated file will be saved as {final_jsonl_filepath}\")\n",
    "\n",
    "# Open the output file once and write to it as we find JSONL files\n",
    "with open(final_jsonl_filepath, 'a') as f_out:\n",
    "    # Walk through the directory structure\n",
    "    for root, dirs, files in os.walk(base_directory):\n",
    "        print(f\"Checking directory: {root}\")\n",
    "        # Filter and process only JSONL files\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.jsonl'):  # This makes the check case-insensitive\n",
    "                full_path = os.path.join(root, file)\n",
    "                print(f\"Found JSONL file: {full_path}\")\n",
    "                with open(full_path, 'r') as f_in:\n",
    "                    f_out.write(f_in.read())\n",
    "                print(f\"Added contents of {file} to {final_jsonl_filepath}\")\n",
    "            else:\n",
    "                print(f\"Ignored file: {file}\")\n",
    "\n",
    "print(\"All JSONL files have been successfully concatenated.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
