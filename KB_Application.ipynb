{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Settings:\n",
      "venue_list: Datasets/test_venues_just_royal_opera.xlsx\n",
      "start_year: 1908\n",
      "years_to_crawl: 1\n",
      "newspaper: Dagens nyheter\n",
      "prompt_filepath: oldtimey_touringbot_prompt_for_deployment.txt\n",
      "db_path: Datasets/13.07.test6.db\n",
      "llm_model: gpt-3.5-turbo\n",
      "max_tokens: 1000\n",
      "Collection ID: https://libris.kb.se/m5z2w4lz3m2zxpk#it\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import sqlite3\n",
    "from urllib.parse import quote_plus\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import os\n",
    "from KBDownloader import search_swedish_newspapers, fetch_newspaper_data, save_checkpoint, load_checkpoint\n",
    "\n",
    "# Get today's date\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Load the YAML configuration file\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Assign variables from the YAML configuration\n",
    "venue_list = config['venue_list']\n",
    "start_year = config['start_year']\n",
    "years_to_crawl = config['years_to_crawl']\n",
    "newspaper = config['newspaper']\n",
    "db_path = config['db_path']\n",
    "\n",
    "# Define the newspaper collection IDs\n",
    "NEWSPAPER_COLLECTION_IDS = {\n",
    "    'Dagens nyheter': 'https://libris.kb.se/m5z2w4lz3m2zxpk#it',\n",
    "    'Svenska Dagbladet': 'https://libris.kb.se/2ldhmx8d4mcrlq9#it',\n",
    "    'Aftonbladet': 'https://libris.kb.se/dwpgqn5q03ft91j#it',\n",
    "    'Dagligt Allehanda': 'https://libris.kb.se/9tmqzv3m32xfzcz#it'\n",
    "}\n",
    "\n",
    "# Get the correct collection ID for the specified newspaper\n",
    "collection_id = NEWSPAPER_COLLECTION_IDS.get(newspaper)\n",
    "if not collection_id:\n",
    "    raise ValueError(f\"Invalid newspaper name: {newspaper}\")\n",
    "\n",
    "# Ensure the database file exists\n",
    "if not os.path.exists(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    conn.close()\n",
    "\n",
    "# Load checkpoint if it exists\n",
    "checkpoint = load_checkpoint()\n",
    "start_year = checkpoint['year'] if checkpoint else start_year\n",
    "start_half = checkpoint['half'] if checkpoint else 0\n",
    "start_index = checkpoint['index'] if checkpoint else 0\n",
    "\n",
    "# Print out all the settings from the YAML configuration file\n",
    "print(\"Configuration Settings:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(f\"Collection ID: {collection_id}\")\n",
    "\n",
    "# Load the venue list\n",
    "df = pd.read_excel(venue_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 15:07:28,482 - INFO - Starting fetch_newspaper_data for query: Kungliga Opera, dates: 1908-01-01 to 1908-06-30\n",
      "2024-07-13 15:07:29,000 - INFO - Search results received. Hits: 20\n",
      "2024-07-13 15:07:29,001 - INFO - Extracted 20 URLs from search results\n",
      "2024-07-13 15:07:29,002 - INFO - Table 'newspaper_data' created or already exists\n",
      "2024-07-13 15:07:29,003 - INFO - Processing URL: https://data.kb.se/dark-3693840/part/1/page/2\n",
      "2024-07-13 15:07:29,296 - INFO - Extracted 1 XML URLs\n",
      "2024-07-13 15:07:30,658 - INFO - Fetched XML content for 1 pages\n",
      "2024-07-13 15:07:30,860 - INFO - Inserted or updated row 1 in database\n",
      "2024-07-13 15:07:30,860 - INFO - Inserted or updated row 2 in database\n",
      "2024-07-13 15:07:30,861 - INFO - Inserted or updated row 3 in database\n",
      "2024-07-13 15:07:30,862 - INFO - Committed changes for URL: https://data.kb.se/dark-3693840/part/1/page/2\n",
      "2024-07-13 15:07:30,862 - INFO - Processing URL: https://data.kb.se/dark-3693618/part/1/page/1\n",
      "2024-07-13 15:07:31,260 - INFO - Extracted 1 XML URLs\n",
      "2024-07-13 15:07:32,377 - INFO - Fetched XML content for 1 pages\n",
      "2024-07-13 15:07:32,638 - INFO - Inserted or updated row 4 in database\n",
      "2024-07-13 15:07:32,639 - INFO - Inserted or updated row 5 in database\n",
      "2024-07-13 15:07:32,640 - INFO - Inserted or updated row 6 in database\n",
      "2024-07-13 15:07:32,641 - INFO - Inserted or updated row 7 in database\n",
      "2024-07-13 15:07:32,642 - INFO - Inserted or updated row 8 in database\n",
      "2024-07-13 15:07:32,643 - INFO - Inserted or updated row 9 in database\n",
      "2024-07-13 15:07:32,644 - INFO - Inserted or updated row 10 in database\n",
      "2024-07-13 15:07:32,646 - INFO - Committed changes for URL: https://data.kb.se/dark-3693618/part/1/page/1\n",
      "2024-07-13 15:07:32,646 - INFO - Processing URL: https://data.kb.se/dark-3693712/part/1/page/2\n",
      "2024-07-13 15:07:33,939 - INFO - Extracted 1 XML URLs\n",
      "2024-07-13 15:07:34,995 - INFO - Fetched XML content for 1 pages\n",
      "2024-07-13 15:07:35,348 - INFO - Inserted or updated row 11 in database\n",
      "2024-07-13 15:07:35,349 - INFO - Inserted or updated row 12 in database\n",
      "2024-07-13 15:07:35,350 - INFO - Inserted or updated row 13 in database\n",
      "2024-07-13 15:07:35,351 - INFO - Inserted or updated row 14 in database\n",
      "2024-07-13 15:07:35,352 - INFO - Inserted or updated row 15 in database\n",
      "2024-07-13 15:07:35,352 - INFO - Inserted or updated row 16 in database\n",
      "2024-07-13 15:07:35,353 - INFO - Inserted or updated row 17 in database\n",
      "2024-07-13 15:07:35,354 - INFO - Inserted or updated row 18 in database\n",
      "2024-07-13 15:07:35,355 - INFO - Inserted or updated row 19 in database\n",
      "2024-07-13 15:07:35,356 - INFO - Inserted or updated row 20 in database\n",
      "2024-07-13 15:07:35,356 - INFO - Inserted or updated row 21 in database\n",
      "2024-07-13 15:07:35,357 - INFO - Inserted or updated row 22 in database\n",
      "2024-07-13 15:07:35,358 - INFO - Inserted or updated row 23 in database\n",
      "2024-07-13 15:07:35,358 - INFO - Inserted or updated row 24 in database\n",
      "2024-07-13 15:07:35,361 - INFO - Committed changes for URL: https://data.kb.se/dark-3693712/part/1/page/2\n",
      "2024-07-13 15:07:35,361 - INFO - Processing URL: https://data.kb.se/dark-3693557/part/1/page/3\n",
      "2024-07-13 15:07:35,612 - INFO - Extracted 1 XML URLs\n",
      "2024-07-13 15:07:36,360 - INFO - Fetched XML content for 1 pages\n",
      "2024-07-13 15:07:36,684 - INFO - Inserted or updated row 25 in database\n",
      "2024-07-13 15:07:36,685 - INFO - Inserted or updated row 26 in database\n",
      "2024-07-13 15:07:36,685 - INFO - Inserted or updated row 27 in database\n",
      "2024-07-13 15:07:36,687 - INFO - Inserted or updated row 28 in database\n",
      "2024-07-13 15:07:36,687 - INFO - Inserted or updated row 29 in database\n",
      "2024-07-13 15:07:36,688 - INFO - Inserted or updated row 30 in database\n",
      "2024-07-13 15:07:36,689 - INFO - Inserted or updated row 31 in database\n",
      "2024-07-13 15:07:36,691 - INFO - Committed changes for URL: https://data.kb.se/dark-3693557/part/1/page/3\n",
      "2024-07-13 15:07:36,691 - INFO - Processing URL: https://data.kb.se/dark-3693450/part/1/page/2\n",
      "2024-07-13 15:07:37,038 - INFO - Extracted 1 XML URLs\n",
      "2024-07-13 15:07:37,811 - INFO - Fetched XML content for 1 pages\n",
      "2024-07-13 15:07:37,997 - INFO - Inserted or updated row 32 in database\n",
      "2024-07-13 15:07:37,998 - INFO - Inserted or updated row 33 in database\n",
      "2024-07-13 15:07:37,999 - INFO - Inserted or updated row 34 in database\n",
      "2024-07-13 15:07:38,000 - INFO - Inserted or updated row 35 in database\n",
      "2024-07-13 15:07:38,001 - INFO - Inserted or updated row 36 in database\n",
      "2024-07-13 15:07:38,001 - INFO - Inserted or updated row 37 in database\n",
      "2024-07-13 15:07:38,002 - INFO - Inserted or updated row 38 in database\n",
      "2024-07-13 15:07:38,003 - INFO - Inserted or updated row 39 in database\n",
      "2024-07-13 15:07:38,003 - INFO - Inserted or updated row 40 in database\n",
      "2024-07-13 15:07:38,004 - INFO - Inserted or updated row 41 in database\n",
      "2024-07-13 15:07:38,005 - INFO - Inserted or updated row 42 in database\n",
      "2024-07-13 15:07:38,006 - INFO - Inserted or updated row 43 in database\n",
      "2024-07-13 15:07:38,007 - INFO - Committed changes for URL: https://data.kb.se/dark-3693450/part/1/page/2\n",
      "2024-07-13 15:07:38,008 - INFO - Processing URL: https://data.kb.se/dark-3693633/part/1/page/2\n",
      "2024-07-13 15:07:38,365 - INFO - Extracted 1 XML URLs\n",
      "2024-07-13 15:07:39,612 - INFO - Fetched XML content for 1 pages\n",
      "2024-07-13 15:07:39,922 - INFO - Inserted or updated row 44 in database\n",
      "2024-07-13 15:07:39,922 - INFO - Inserted or updated row 45 in database\n",
      "2024-07-13 15:07:39,923 - INFO - Inserted or updated row 46 in database\n",
      "2024-07-13 15:07:39,924 - INFO - Inserted or updated row 47 in database\n",
      "2024-07-13 15:07:39,925 - INFO - Committed changes for URL: https://data.kb.se/dark-3693633/part/1/page/2\n",
      "2024-07-13 15:07:39,926 - INFO - Processing URL: https://data.kb.se/dark-3693573/part/1/page/3\n",
      "2024-07-13 15:07:40,271 - INFO - Extracted 1 XML URLs\n",
      "2024-07-13 15:07:41,308 - INFO - Fetched XML content for 1 pages\n",
      "2024-07-13 15:07:41,607 - INFO - Inserted or updated row 48 in database\n",
      "2024-07-13 15:07:41,608 - INFO - Inserted or updated row 49 in database\n",
      "2024-07-13 15:07:41,609 - INFO - Committed changes for URL: https://data.kb.se/dark-3693573/part/1/page/3\n",
      "2024-07-13 15:07:41,610 - INFO - Processing URL: https://data.kb.se/dark-3693727/part/1/page/3\n",
      "2024-07-13 15:07:41,881 - INFO - Extracted 1 XML URLs\n",
      "2024-07-13 15:07:43,261 - INFO - Fetched XML content for 1 pages\n",
      "2024-07-13 15:07:43,504 - INFO - Inserted or updated row 50 in database\n",
      "2024-07-13 15:07:43,505 - INFO - Inserted or updated row 51 in database\n",
      "2024-07-13 15:07:43,506 - INFO - Inserted or updated row 52 in database\n",
      "2024-07-13 15:07:43,508 - INFO - Inserted or updated row 53 in database\n",
      "2024-07-13 15:07:43,509 - INFO - Committed changes for URL: https://data.kb.se/dark-3693727/part/1/page/3\n",
      "2024-07-13 15:07:43,509 - INFO - Processing URL: https://data.kb.se/dark-3693490/part/1/page/1\n",
      "2024-07-13 15:07:43,761 - INFO - Extracted 1 XML URLs\n",
      "2024-07-13 15:07:44,441 - INFO - Fetched XML content for 1 pages\n",
      "2024-07-13 15:07:44,607 - INFO - Inserted or updated row 54 in database\n",
      "2024-07-13 15:07:44,607 - INFO - Inserted or updated row 55 in database\n",
      "2024-07-13 15:07:44,608 - INFO - Inserted or updated row 56 in database\n",
      "2024-07-13 15:07:44,609 - INFO - Committed changes for URL: https://data.kb.se/dark-3693490/part/1/page/1\n",
      "2024-07-13 15:07:44,610 - INFO - Processing URL: https://data.kb.se/dark-3693621/part/1/page/1\n",
      "2024-07-13 15:07:44,970 - INFO - Extracted 1 XML URLs\n",
      "2024-07-13 15:07:47,541 - INFO - Fetched XML content for 1 pages\n",
      "2024-07-13 15:07:47,860 - INFO - Inserted or updated row 57 in database\n",
      "2024-07-13 15:07:47,860 - INFO - Inserted or updated row 58 in database\n",
      "2024-07-13 15:07:47,861 - INFO - Inserted or updated row 59 in database\n",
      "2024-07-13 15:07:47,862 - INFO - Inserted or updated row 60 in database\n",
      "2024-07-13 15:07:47,863 - INFO - Inserted or updated row 61 in database\n",
      "2024-07-13 15:07:47,864 - INFO - Committed changes for URL: https://data.kb.se/dark-3693621/part/1/page/1\n",
      "2024-07-13 15:07:47,865 - INFO - Processing URL: https://data.kb.se/dark-3693635/part/1/page/3\n",
      "2024-07-13 15:07:48,145 - INFO - Extracted 1 XML URLs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m safe_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([c \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39misalnum() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m query])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_newspaper_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mto_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_date\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnewspaper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_path\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed query \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Post-Phd/Quantitative Work/Software/Oldtimey_touringbot/KBDownloader.py:341\u001b[0m, in \u001b[0;36mfetch_newspaper_data\u001b[0;34m(query, from_date, to_date, newspaper, config, db_path)\u001b[0m\n\u001b[1;32m    338\u001b[0m xml_urls \u001b[38;5;241m=\u001b[39m extract_xml_urls(api_response, [page_id])\n\u001b[1;32m    339\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(xml_urls)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m XML URLs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 341\u001b[0m xml_content_by_page \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_xml_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxml_urls\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetched XML content for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(xml_content_by_page)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m pages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_number, xml_content \u001b[38;5;129;01min\u001b[39;00m xml_content_by_page\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Post-Phd/Quantitative Work/Software/Oldtimey_touringbot/KBDownloader.py:70\u001b[0m, in \u001b[0;36mfetch_xml_content\u001b[0;34m(xml_urls, max_retries, initial_delay)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retries \u001b[38;5;241m<\u001b[39m max_retries:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     72\u001b[0m             xml_content_by_page[page_number] \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/sessions.py:745\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 745\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 465\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main loop\n",
    "for year in range(start_year, start_year + years_to_crawl):\n",
    "    for half in range(2):\n",
    "        if year == start_year and half < start_half:\n",
    "            continue\n",
    "        \n",
    "        if half == 0:\n",
    "            from_date = datetime(year, 1, 1)\n",
    "            to_date = datetime(year, 6, 30)\n",
    "        else:\n",
    "            from_date = datetime(year, 7, 1)\n",
    "            to_date = datetime(year, 12, 31)\n",
    "\n",
    "        for index, row in df.iloc[start_index:].iterrows():\n",
    "            query = row['Lokal']\n",
    "            safe_query = \"\".join([c if c.isalnum() else \"_\" for c in query])\n",
    "\n",
    "            \n",
    "            try:\n",
    "                result = fetch_newspaper_data(\n",
    "                    query=query,\n",
    "                    from_date=from_date.strftime('%Y-%m-%d'),\n",
    "                    to_date=to_date.strftime('%Y-%m-%d'),\n",
    "                    newspaper=collection_id,\n",
    "                    config=config,\n",
    "                    db_path=db_path\n",
    "                )\n",
    "                \n",
    "                if result.get('success'):\n",
    "                    print(f\"Processed query '{query}' successfully.\")\n",
    "                else:\n",
    "                    print(f\"Failed to process query '{query}': {result.get('message')}\")\n",
    "                \n",
    "                # Save checkpoint after each query, successful or not\n",
    "                save_checkpoint(year, half, index + 1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing query '{query}': {str(e)}\")\n",
    "                save_checkpoint(year, half, index)\n",
    "                raise  # Re-raise the exception to stop the script\n",
    "\n",
    "        print(f\"Waiting. Currently at {from_date} to {to_date}\")\n",
    "        time.sleep(3) # in seconds\n",
    "        start_index = 0  # Reset start_index for the next half-year\n",
    "\n",
    "    start_half = 0  # Reset start_half for the next year\n",
    "\n",
    "print(\"All queries processed for all specified years.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# SQL query to select all columns except 'Raw API Result'\n",
    "query = \"\"\"\n",
    "SELECT Date, [Package ID], Part, Page, [ComposedBlock Content], [Full Prompt]\n",
    "FROM newspaper_data\n",
    "\"\"\"\n",
    "\n",
    "# Read the query results into a pandas DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(df.info())\n",
    "\n",
    "# Optional: If you want to see all rows, you can use:\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# print(df)\n",
    "\n",
    "# Optional: If you want to save this to a CSV file for further analysis:\n",
    "# df.to_csv('newspaper_data_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
